{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ../input/kaushals-models/timm-0.4.9/timm-0.4.9.tar\nimport os\nimport re\nimport cv2\nimport math\nimport random\nimport numpy as np\nimport pandas as pd\nimport gc\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pickle\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport timm\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nfrom transformers import AutoTokenizer, AutoModel\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.neighbors import NearestNeighbors\nimport sys","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-29T09:44:57.539816Z","iopub.execute_input":"2021-05-29T09:44:57.540160Z","iopub.status.idle":"2021-05-29T09:45:24.849448Z","shell.execute_reply.started":"2021-05-29T09:44:57.540115Z","shell.execute_reply":"2021-05-29T09:45:24.848509Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/kaushals-models/timm-0.4.9/timm-0.4.9.tar\nRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm==0.4.9) (1.7.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm==0.4.9) (0.8.1)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.9) (0.18.2)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.9) (3.7.4.3)\nRequirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.9) (0.6)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.9) (1.19.5)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.4.9) (7.2.0)\n\u001b[33mDEPRECATION: Source distribution is being reinstalled despite an installed package having the same name and version as the installed package. pip 21.1 will remove support for this functionality. A possible replacement is use --force-reinstall. You can find discussion regarding this at https://github.com/pypa/pip/issues/8711.\u001b[0m\nBuilding wheels for collected packages: timm\n  Building wheel for timm (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for timm: filename=timm-0.4.9-py3-none-any.whl size=342009 sha256=fe1bfe094bea6f1559fe676171a6df3fc1b32b74c8e2dcb727e609d95ad8d159\n  Stored in directory: /root/.cache/pip/wheels/0d/b7/f6/e62466e745f695231eeebed8ec233b0b49fc0c9e896359c668\nSuccessfully built timm\nInstalling collected packages: timm\n  Attempting uninstall: timm\n    Found existing installation: timm 0.4.9\n    Uninstalling timm-0.4.9:\n      Successfully uninstalled timm-0.4.9\nSuccessfully installed timm-0.4.9\n","output_type":"stream"}]},{"cell_type":"code","source":"class CFG:\n    compute_cv = True  # set False to fast save\n    todo_predictions = ['predictions']\n    \n    ### CNN and BERT\n    use_amp = True\n    scale = 30  # ArcFace\n    margin = 0.5  # ArcFace\n    seed = 2021\n    classes = 11014\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    print(device)\n    \n    ### CNN 1\n    model_name = 'eca_nfnet_l0'\n    img_size = 380\n    batch_size = 32\n    model_path = '../input/kaushals-models/arcface_512x512_nfnet_l0 (mish).pt'\n    num_tta = 3\n    fc_dim = 512\n    cnn_use_fc = True\n    \n    ### BERT 1\n    if 'kaggle_web_client' in sys.modules:\n        bert_model_name = '../input/bertmodel/paraphrase-xlm-r-multilingual-v1'  # for kaggle notebook\n    else:\n        bert_model_name = 'sentence-transformers/paraphrase-xlm-r-multilingual-v1'\n    bert_model_path = '../input/kaushals-models/BERT_model2.pt'\n    max_length = 128\n    bert_batch_size = 32\n    bert_fc_dim = 768\n    bert_use_fc = True\n    \n    ### BERT 2\n\n    bert_model_name2 = '../input/bertmodel/distilbert-base-indonesian'  # for kaggle notebook\n\n    bert_model_path2 = '../input/kaushals-models/indonesian_bert.pt'\n    max_length2 = 128\n    bert_batch_size2 = 32\n    bert_fc_dim2 = 768\n    bert_use_fc2 = True\n    \n    ### Prediction\n    cnn_threshold = 0.84\n    bert_threshold = 0.84\n    chunk = 32\n    max_preds = 42\n    nearlest_one = True # True is better\n        \n    ### Data\n    \n    train_csv_path = '../input/shopee-product-matching/train.csv'\n    test_csv_path = '../input/shopee-product-matching/test.csv'\n    \n    if compute_cv == True:\n        images_dir = '../input/shopee-product-matching/train_images/'\n    else:\n        images_dir = '../input/shopee-product-matching/test_images/'\n\n    if 'kaggle_web_client' in sys.modules:\n        num_workers = 4\n    else:\n        num_workers = 0  # for Windows 10","metadata":{"execution":{"iopub.status.busy":"2021-05-29T09:45:24.851575Z","iopub.execute_input":"2021-05-29T09:45:24.851938Z","iopub.status.idle":"2021-05-29T09:45:24.907765Z","shell.execute_reply.started":"2021-05-29T09:45:24.851901Z","shell.execute_reply":"2021-05-29T09:45:24.906892Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True # set True to be faster\n\nseed_everything(CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T09:45:24.909778Z","iopub.execute_input":"2021-05-29T09:45:24.910550Z","iopub.status.idle":"2021-05-29T09:45:24.921474Z","shell.execute_reply.started":"2021-05-29T09:45:24.910485Z","shell.execute_reply":"2021-05-29T09:45:24.920714Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def read_dataset():\n    \n    df = pd.read_csv(CFG.test_csv_path)\n    \n    if len(df) > 3:\n        CFG.compute_cv = False\n        CFG.images_dir = '../input/shopee-product-matching/test_images/'\n    \n    if CFG.compute_cv == True:\n        df = pd.read_csv(CFG.train_csv_path)\n        print('Using train as test to compute CV. Shape is', df.shape)\n    else:\n        print('Test shape is', df.shape )\n    \n    image_paths = CFG.images_dir + df['image']\n\n    return df, image_paths","metadata":{"execution":{"iopub.status.busy":"2021-05-29T09:45:24.922850Z","iopub.execute_input":"2021-05-29T09:45:24.923520Z","iopub.status.idle":"2021-05-29T09:45:24.930301Z","shell.execute_reply.started":"2021-05-29T09:45:24.923482Z","shell.execute_reply":"2021-05-29T09:45:24.929539Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def f1_score(y_true, y_pred):\n    y_true = y_true.apply(lambda x: set(x.split()))\n    y_pred = y_pred.apply(lambda x: set(x.split()))\n    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n    len_y_pred = y_pred.apply(lambda x: len(x)).values\n    len_y_true = y_true.apply(lambda x: len(x)).values\n    f1 = 2 * intersection / (len_y_pred + len_y_true)\n    return f1","metadata":{"execution":{"iopub.status.busy":"2021-05-29T09:45:24.931735Z","iopub.execute_input":"2021-05-29T09:45:24.932442Z","iopub.status.idle":"2021-05-29T09:45:24.939691Z","shell.execute_reply.started":"2021-05-29T09:45:24.932391Z","shell.execute_reply":"2021-05-29T09:45:24.938836Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class ArcMarginProduct(nn.Module):\n    def __init__(self, in_features, out_features, scale=30.0, margin=0.50, easy_margin=False, ls_eps=0.0):\n        super(ArcMarginProduct, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scale = scale\n        self.margin = margin\n        self.ls_eps = ls_eps  # label smoothing\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n\n        self.easy_margin = easy_margin\n        self.cos_m = math.cos(margin)\n        self.sin_m = math.sin(margin)\n        self.th = math.cos(math.pi - margin)\n        self.mm = math.sin(math.pi - margin) * margin\n        \n        self.criterion = nn.CrossEntropyLoss()\n        \n    def forward(self, input, label):\n        # --------------------------- cos(theta) & phi(theta) ---------------------------\n        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n        # --------------------------- convert label to one-hot ---------------------------\n        one_hot = torch.zeros(cosine.size(), device=CFG.device)\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.scale\n        return output, self.criterion(output,label)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T09:45:24.941051Z","iopub.execute_input":"2021-05-29T09:45:24.941537Z","iopub.status.idle":"2021-05-29T09:45:24.954320Z","shell.execute_reply.started":"2021-05-29T09:45:24.941503Z","shell.execute_reply":"2021-05-29T09:45:24.953265Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def mean_pooling(model_output, attention_mask):\n    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n    return sum_embeddings / sum_mask\n\n\nclass ShopeeBertModel(nn.Module):\n\n    def __init__(\n        self,\n        n_classes = CFG.classes,\n        model_name = None,\n        fc_dim = 768,\n        margin = CFG.margin,\n        scale = CFG.scale,\n        use_fc = True        \n    ):\n\n        super(ShopeeBertModel,self).__init__()\n        print('Building Model Backbone for {} model'.format(model_name))\n\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.backbone = AutoModel.from_pretrained(model_name).to(CFG.device)\n\n        in_features = 768\n        self.use_fc = use_fc\n        \n        self.dropout = nn.Dropout(p=0.1)\n        self.classifier = nn.Linear(in_features, fc_dim)\n        self.bn = nn.BatchNorm1d(fc_dim)\n        self._init_params()\n        in_features = fc_dim\n            \n        self.final = ArcMarginProduct(\n            in_features,\n            n_classes,\n            scale = scale,\n            margin = margin,\n            easy_margin = False,\n            ls_eps = 0.0\n        )\n\n    def _init_params(self):\n        nn.init.xavier_normal_(self.classifier.weight)\n        nn.init.constant_(self.classifier.bias, 0)\n        nn.init.constant_(self.bn.weight, 1)\n        nn.init.constant_(self.bn.bias, 0)\n\n    def forward(self, texts, labels=torch.tensor([0])):\n        features = self.extract_features(texts)\n        if self.training:\n            logits = self.final(features, labels.to(CFG.device))\n            return logits\n        else:\n            return features\n        \n    def extract_features(self, texts):\n        encoding = self.tokenizer(texts, padding=True, truncation=True,\n                             max_length=CFG.max_length, return_tensors='pt').to(CFG.device)\n        input_ids = encoding['input_ids']\n        attention_mask = encoding['attention_mask']\n        embedding = self.backbone(input_ids, attention_mask=attention_mask)\n        x = mean_pooling(embedding, attention_mask)\n        \n        if self.use_fc:\n            x = self.dropout(x)\n            x = self.classifier(x)\n            x = self.bn(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-05-29T09:45:24.956791Z","iopub.execute_input":"2021-05-29T09:45:24.957145Z","iopub.status.idle":"2021-05-29T09:45:24.978057Z","shell.execute_reply.started":"2021-05-29T09:45:24.957110Z","shell.execute_reply":"2021-05-29T09:45:24.977224Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def get_bert_embeddings(df,column, model_name, model_path, fc_dim=768, use_fc=True, chunk=32):\n    \n    print('Getting BERT ArcFace embeddings...')\n    \n    model = ShopeeBertModel(model_name=model_name, fc_dim=fc_dim, use_fc=use_fc)\n    model.to(CFG.device)\n    model.load_state_dict(torch.load(model_path, map_location=CFG.device))\n    model.eval()\n    \n    bert_embeddings = torch.zeros((df.shape[0], 768)).to(CFG.device)\n    for i in tqdm(list(range(0, df.shape[0], chunk)) + [df.shape[0]-chunk], ncols=100):\n        titles = []\n        for title in df[column][i : i + chunk].values:\n            try:\n                title = ' ' + title.encode('utf-8').decode(\"unicode_escape\").encode('ascii', 'ignore').decode(\"unicode_escape\") + ' '\n            except:\n                pass\n            title = title.lower()\n            \n            titles.append(title)\n            \n        with torch.no_grad():\n            if CFG.use_amp:\n                with torch.cuda.amp.autocast():\n                    model_output = model(titles)\n            else:\n                model_output = model(titles)\n            \n        bert_embeddings[i : i + chunk] = model_output\n    \n    del model, titles, model_output\n    gc.collect()\n    torch.cuda.empty_cache()\n    \n    return bert_embeddings\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T09:45:24.979532Z","iopub.execute_input":"2021-05-29T09:45:24.979870Z","iopub.status.idle":"2021-05-29T09:45:24.989936Z","shell.execute_reply.started":"2021-05-29T09:45:24.979835Z","shell.execute_reply":"2021-05-29T09:45:24.989040Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class ShopeeCNNModel(nn.Module):\n\n    def __init__(\n        self,\n        n_classes = CFG.classes,\n        model_name = CFG.model_name,\n        fc_dim = CFG.fc_dim,\n        margin = CFG.margin,\n        scale = CFG.scale,\n        use_fc = True,\n        pretrained = False,\n        training=True):\n\n\n        super(ShopeeCNNModel,self).__init__()\n        print('Building Model Backbone for {} model'.format(model_name))\n        self.training=training\n        self.backbone = torch.load('../input/kaushals-models/nfnet.pt')\n\n        if model_name == 'resnext50_32x4d':\n            final_in_features = self.backbone.fc.in_features\n            self.backbone.fc = nn.Identity()\n            self.backbone.global_pool = nn.Identity()\n\n        elif 'efficientnet' in model_name:\n            final_in_features = self.backbone.classifier.in_features\n            self.backbone.classifier = nn.Identity()\n            self.backbone.global_pool = nn.Identity()\n        \n        elif 'nfnet' in model_name:\n            final_in_features = self.backbone.head.fc.in_features\n            self.backbone.head.fc = nn.Identity()\n            self.backbone.head.global_pool = nn.Identity()\n\n        self.pooling =  nn.AdaptiveAvgPool2d(1)\n\n        self.use_fc = use_fc\n\n        if use_fc:\n            self.dropout = nn.Dropout(p=0.0)\n            self.fc = nn.Linear(final_in_features, fc_dim)\n            self.bn = nn.BatchNorm1d(fc_dim)\n            self._init_params()\n            final_in_features = fc_dim\n\n        self.final = ArcMarginProduct(\n            final_in_features,\n            n_classes,\n            scale = scale,\n            margin = margin,\n            easy_margin = False,\n            ls_eps = 0.0\n        )\n\n    def _init_params(self):\n        nn.init.xavier_normal_(self.fc.weight)\n        nn.init.constant_(self.fc.bias, 0)\n        nn.init.constant_(self.bn.weight, 1)\n        nn.init.constant_(self.bn.bias, 0)\n\n    def forward(self, image, label):\n        feature = self.extract_feat(image)\n        if self.training:\n          logits = self.final(feature,label)\n          return logits\n        return feature\n\n    def extract_feat(self, x):\n        batch_size = x.shape[0]\n        x = self.backbone(x)\n        x = self.pooling(x).view(batch_size, -1)\n\n        if self.use_fc:\n            x = self.dropout(x)\n            x = self.fc(x)\n            x = self.bn(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-05-29T09:45:24.991504Z","iopub.execute_input":"2021-05-29T09:45:24.992264Z","iopub.status.idle":"2021-05-29T09:45:25.006794Z","shell.execute_reply.started":"2021-05-29T09:45:24.992204Z","shell.execute_reply":"2021-05-29T09:45:25.006079Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def get_valid_transforms(img_size=512):\n\n    return albumentations.Compose([\n        albumentations.Resize(img_size, img_size, p=1.),\n        albumentations.Normalize(\n            mean = [0.485, 0.456, 0.406],\n            std = [0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0\n        ),\n        ToTensorV2(p=1.0)\n    ])\n\ndef get_test_transforms(img_size=512):\n\n    return albumentations.Compose([\n        albumentations.RandomResizedCrop(img_size, img_size, scale=(0.6, 1.0), ratio=(1.0, 1.0)),\n        albumentations.Normalize(\n            mean = [0.485, 0.456, 0.406],\n            std = [0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0\n        ),\n        ToTensorV2(p=1.0)\n    ])","metadata":{"execution":{"iopub.status.busy":"2021-05-29T09:45:25.008127Z","iopub.execute_input":"2021-05-29T09:45:25.008610Z","iopub.status.idle":"2021-05-29T09:45:25.019118Z","shell.execute_reply.started":"2021-05-29T09:45:25.008573Z","shell.execute_reply":"2021-05-29T09:45:25.018202Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class ShopeeTestImageDataset(Dataset):\n\n    def __init__(self, image_paths, transforms=None):\n        self.image_paths = image_paths\n        self.transform = transforms\n\n    def __len__(self):\n        return self.image_paths.shape[0]\n\n    def __getitem__(self, index):\n        image_path = self.image_paths[index]\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        \n        return image","metadata":{"execution":{"iopub.status.busy":"2021-05-29T09:45:25.021640Z","iopub.execute_input":"2021-05-29T09:45:25.021921Z","iopub.status.idle":"2021-05-29T09:45:25.030297Z","shell.execute_reply.started":"2021-05-29T09:45:25.021888Z","shell.execute_reply":"2021-05-29T09:45:25.029377Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def get_cnn_embeddings(model, dataloader):\n    model.eval()\n    embeds = []\n    for _, image in tqdm(enumerate(dataloader), total=len(dataloader), desc=\"get_cnn_embeddings\", ncols=80): \n        img = image.to(CFG.device)\n\n        with torch.no_grad():\n            if CFG.use_amp:\n                with torch.cuda.amp.autocast():\n                    features = model(img, torch.tensor([1]))\n            else:\n                features = model(img, torch.tensor([1]))\n\n        embeddings = features.detach().cpu().numpy().astype('float32')\n        embeds.append(embeddings)\n\n    del model\n    embeddings = np.concatenate(embeds)\n    del embeds\n    gc.collect()\n    return embeddings","metadata":{"execution":{"iopub.status.busy":"2021-05-29T09:45:25.031501Z","iopub.execute_input":"2021-05-29T09:45:25.032036Z","iopub.status.idle":"2021-05-29T09:45:25.040431Z","shell.execute_reply.started":"2021-05-29T09:45:25.032000Z","shell.execute_reply":"2021-05-29T09:45:25.039420Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def get_predictions(df, cnn_embeddings_mean_half, bert_embeddings_half, cnn_threshold=1.0, bert_threshold=1.0, chunk=32, nearlest_one=True, max_preds=50):\n    print('Finding similar ones...')\n    CTS = len(df) // chunk\n    if (len(df) % chunk) != 0:\n        CTS += 1\n        \n    preds = []\n    for j in tqdm(range(CTS)):\n        a = j * chunk\n        b = min((j+1) * chunk, len(df))\n        cnn_cts = torch.matmul(cnn_embeddings_mean_half, cnn_embeddings_mean_half[a:b].T).T\n        bert_cts = torch.matmul(bert_embeddings_half, bert_embeddings_half[a:b].T).T\n        \n        for k in range(b-a):\n            sim = (cnn_cts[k,] / cnn_threshold) ** 6 + (bert_cts[k,] / bert_threshold) ** 6\n            sim_desc = torch.sort(sim, descending=True)\n            \n            IDX = sim_desc[1][sim_desc[0] > 1][:max_preds].cpu().detach().numpy()\n            o = df.iloc[IDX].posting_id.values\n            \n            if (len(IDX) == 1) and nearlest_one:\n                IDX = sim_desc[1][:2].cpu().detach().numpy()\n                o = df.iloc[IDX].posting_id.values\n            \n            preds.append(o)\n\n    del cnn_cts, bert_cts\n    gc.collect()\n    torch.cuda.empty_cache()\n    \n    return preds","metadata":{"execution":{"iopub.status.busy":"2021-05-29T09:45:25.041800Z","iopub.execute_input":"2021-05-29T09:45:25.042159Z","iopub.status.idle":"2021-05-29T09:45:25.053051Z","shell.execute_reply.started":"2021-05-29T09:45:25.042117Z","shell.execute_reply":"2021-05-29T09:45:25.052043Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"data,image_paths=read_dataset()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T09:45:42.895054Z","iopub.execute_input":"2021-05-29T09:45:42.895385Z","iopub.status.idle":"2021-05-29T09:45:43.061319Z","shell.execute_reply.started":"2021-05-29T09:45:42.895352Z","shell.execute_reply":"2021-05-29T09:45:43.059732Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Using train as test to compute CV. Shape is (34250, 5)\n","output_type":"stream"}]},{"cell_type":"code","source":"bert_embeddings = get_bert_embeddings(data,column='title', model_name=CFG.bert_model_name, model_path=CFG.bert_model_path,\n                                      fc_dim=CFG.bert_fc_dim, use_fc=CFG.bert_use_fc, chunk=CFG.bert_batch_size)\nprint('bert_embeddings.shape:', bert_embeddings.shape)","metadata":{"execution":{"iopub.status.busy":"2021-05-29T09:45:44.799020Z","iopub.execute_input":"2021-05-29T09:45:44.799358Z","iopub.status.idle":"2021-05-29T09:47:05.278867Z","shell.execute_reply.started":"2021-05-29T09:45:44.799327Z","shell.execute_reply":"2021-05-29T09:47:05.276727Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Getting BERT ArcFace embeddings...\nBuilding Model Backbone for ../input/bertmodel/paraphrase-xlm-r-multilingual-v1 model\n","output_type":"stream"},{"name":"stderr","text":"100%|███████████████████████████████████████████████████████████| 1072/1072 [00:48<00:00, 22.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"bert_embeddings.shape: torch.Size([34250, 768])\n","output_type":"stream"}]},{"cell_type":"code","source":"bert_embeddings2 = get_bert_embeddings(data,column='title', model_name=CFG.bert_model_name2, model_path=CFG.bert_model_path2,\n                                       fc_dim=CFG.bert_fc_dim2, use_fc=CFG.bert_use_fc2, chunk=CFG.bert_batch_size2)\nprint('bert_embeddings2.shape:', bert_embeddings2.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T09:47:05.280435Z","iopub.execute_input":"2021-05-29T09:47:05.280780Z","iopub.status.idle":"2021-05-29T09:47:36.936258Z","shell.execute_reply.started":"2021-05-29T09:47:05.280743Z","shell.execute_reply":"2021-05-29T09:47:36.935448Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Getting BERT ArcFace embeddings...\nBuilding Model Backbone for ../input/bertmodel/distilbert-base-indonesian model\n","output_type":"stream"},{"name":"stderr","text":"100%|███████████████████████████████████████████████████████████| 1072/1072 [00:23<00:00, 46.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"bert_embeddings2.shape: torch.Size([34250, 768])\n","output_type":"stream"}]},{"cell_type":"code","source":"def replace_activations(model, existing_layer, new_layer):\n    \n    \"\"\"A function for replacing existing activation layers\"\"\"\n    \n    for name, module in reversed(model._modules.items()):\n        if len(list(module.children())) > 0:\n            model._modules[name] = replace_activations(module, existing_layer, new_layer)\n\n        if type(module) == existing_layer:\n            layer_old = module\n            layer_new = new_layer\n            model._modules[name] = layer_new\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-05-29T09:49:38.285923Z","iopub.execute_input":"2021-05-29T09:49:38.286567Z","iopub.status.idle":"2021-05-29T09:49:38.301477Z","shell.execute_reply.started":"2021-05-29T09:49:38.286519Z","shell.execute_reply":"2021-05-29T09:49:38.298603Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class Mish_func(torch.autograd.Function):\n    \n    \"\"\"from: https://github.com/tyunist/memory_efficient_mish_swish/blob/master/mish.py\"\"\"\n    \n    @staticmethod\n    def forward(ctx, i):\n        result = i * torch.tanh(F.softplus(i))\n        ctx.save_for_backward(i)\n        return result\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        i = ctx.saved_variables[0]\n  \n        v = 1. + i.exp()\n        h = v.log() \n        grad_gh = 1./h.cosh().pow_(2) \n\n        # Note that grad_hv * grad_vx = sigmoid(x)\n        #grad_hv = 1./v  \n        #grad_vx = i.exp()\n        \n        grad_hx = i.sigmoid()\n\n        grad_gx = grad_gh *  grad_hx #grad_hv * grad_vx \n        \n        grad_f =  torch.tanh(F.softplus(i)) + i * grad_gx \n        \n        return grad_output * grad_f \n\n\nclass Mish(nn.Module):\n    def __init__(self, **kwargs):\n        super().__init__()\n        pass\n    def forward(self, input_tensor):\n        return Mish_func.apply(input_tensor)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-29T09:48:29.095794Z","iopub.execute_input":"2021-05-29T09:48:29.096125Z","iopub.status.idle":"2021-05-29T09:48:29.104677Z","shell.execute_reply.started":"2021-05-29T09:48:29.096095Z","shell.execute_reply":"2021-05-29T09:48:29.103750Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model = ShopeeCNNModel()\nmodel = replace_activations(model, torch.nn.SiLU, Mish())\nmodel.to(CFG.device)\nmodel.load_state_dict(torch.load(CFG.model_path, map_location=CFG.device))\ncnn_embeddings_all = []\n\nfor tta in range(CFG.num_tta):\n    if tta == 0:\n        test_dataset = ShopeeTestImageDataset(image_paths=image_paths, transforms=get_valid_transforms(img_size=CFG.img_size))\n    else:\n        test_dataset = ShopeeTestImageDataset(image_paths=image_paths, transforms=get_test_transforms(img_size=CFG.img_size))\n\n    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=CFG.batch_size, num_workers=CFG.num_workers,\n                                                  pin_memory=True, shuffle=False, drop_last=False)\n    cnn_embeddings = get_cnn_embeddings(model, test_dataloader)\n\n    cnn_embeddings_all.append(cnn_embeddings)\n\ndel cnn_embeddings\n\ncnn_embeddings_mean = np.mean(cnn_embeddings_all, axis=0)\nprint('cnn_embeddings_mean.shape:', cnn_embeddings_mean.shape)\n\ndel cnn_embeddings_all\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-05-29T09:49:43.699903Z","iopub.execute_input":"2021-05-29T09:49:43.700231Z","iopub.status.idle":"2021-05-29T10:10:25.864955Z","shell.execute_reply.started":"2021-05-29T09:49:43.700200Z","shell.execute_reply":"2021-05-29T10:10:25.863541Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Building Model Backbone for eca_nfnet_l0 model\n","output_type":"stream"},{"name":"stderr","text":"get_cnn_embeddings: 100%|███████████████████| 1071/1071 [07:04<00:00,  2.52it/s]\nget_cnn_embeddings: 100%|███████████████████| 1071/1071 [06:48<00:00,  2.62it/s]\nget_cnn_embeddings: 100%|███████████████████| 1071/1071 [06:46<00:00,  2.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"cnn_embeddings_mean.shape: (34250, 512)\n","output_type":"stream"}]},{"cell_type":"code","source":"cnn_embeddings_mean_half = torch.tensor(cnn_embeddings_mean, dtype=torch.float16).to(CFG.device)\n\nbert_embeddings_half = (bert_embeddings.to(torch.float16) + bert_embeddings2.to(torch.float16)) / 2\n\npredictions = get_predictions(data,\n                              F.normalize(cnn_embeddings_mean_half),\n                              F.normalize(bert_embeddings_half),\n                              cnn_threshold=CFG.cnn_threshold,\n                              bert_threshold=CFG.bert_threshold,\n                              chunk=CFG.chunk,\n                              max_preds=CFG.max_preds,\n                              nearlest_one=CFG.nearlest_one)\n\ndata['predictions'] = predictions","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:12:05.259811Z","iopub.execute_input":"2021-05-29T10:12:05.260136Z","iopub.status.idle":"2021-05-29T10:12:38.534465Z","shell.execute_reply.started":"2021-05-29T10:12:05.260107Z","shell.execute_reply":"2021-05-29T10:12:38.533633Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"  0%|          | 4/1071 [00:00<00:32, 32.91it/s]","output_type":"stream"},{"name":"stdout","text":"Finding similar ones...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1071/1071 [00:33<00:00, 32.42it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def combine_predictions(row):\n    x = np.concatenate([row[col] for col in CFG.todo_predictions])\n    return ' '.join( np.unique(x) )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:12:38.535976Z","iopub.execute_input":"2021-05-29T10:12:38.536322Z","iopub.status.idle":"2021-05-29T10:12:38.541517Z","shell.execute_reply.started":"2021-05-29T10:12:38.536284Z","shell.execute_reply":"2021-05-29T10:12:38.540385Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"data['matches'] = data.apply(combine_predictions, axis=1)\ndata[['posting_id', 'matches']].to_csv('submission.csv', index=False)\nsubmission_df = pd.read_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:13:12.389819Z","iopub.execute_input":"2021-05-29T10:13:12.390151Z","iopub.status.idle":"2021-05-29T10:13:13.668793Z","shell.execute_reply.started":"2021-05-29T10:13:12.390121Z","shell.execute_reply":"2021-05-29T10:13:13.667953Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-05-29T10:13:15.519260Z","iopub.execute_input":"2021-05-29T10:13:15.519612Z","iopub.status.idle":"2021-05-29T10:13:15.536341Z","shell.execute_reply.started":"2021-05-29T10:13:15.519583Z","shell.execute_reply":"2021-05-29T10:13:15.535260Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"             posting_id                                            matches\n0       train_129225211                   train_129225211 train_2278313361\n1      train_3386243561                  train_3386243561 train_3423213080\n2      train_2288590299                  train_2288590299 train_3803689425\n3      train_2406599165  train_1508100548 train_1744956981 train_240659...\n4      train_3369186413                   train_3369186413 train_921438619\n...                 ...                                                ...\n34245  train_4028265689                  train_2829161572 train_4028265689\n34246   train_769054909                   train_1463059254 train_769054909\n34247   train_614977732  train_1264798465 train_1589074615 train_232545...\n34248  train_3630949769  train_1431563868 train_3419392575 train_363094...\n34249  train_1792180725                   train_1792180725 train_795128312\n\n[34250 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>posting_id</th>\n      <th>matches</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_129225211</td>\n      <td>train_129225211 train_2278313361</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_3386243561</td>\n      <td>train_3386243561 train_3423213080</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2288590299</td>\n      <td>train_2288590299 train_3803689425</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_2406599165</td>\n      <td>train_1508100548 train_1744956981 train_240659...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_3369186413</td>\n      <td>train_3369186413 train_921438619</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>34245</th>\n      <td>train_4028265689</td>\n      <td>train_2829161572 train_4028265689</td>\n    </tr>\n    <tr>\n      <th>34246</th>\n      <td>train_769054909</td>\n      <td>train_1463059254 train_769054909</td>\n    </tr>\n    <tr>\n      <th>34247</th>\n      <td>train_614977732</td>\n      <td>train_1264798465 train_1589074615 train_232545...</td>\n    </tr>\n    <tr>\n      <th>34248</th>\n      <td>train_3630949769</td>\n      <td>train_1431563868 train_3419392575 train_363094...</td>\n    </tr>\n    <tr>\n      <th>34249</th>\n      <td>train_1792180725</td>\n      <td>train_1792180725 train_795128312</td>\n    </tr>\n  </tbody>\n</table>\n<p>34250 rows × 2 columns</p>\n</div>"},"metadata":{}}]}]}